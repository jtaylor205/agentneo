{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa0oCgeBuM_0"
      },
      "source": [
        "# AgentNeo: Code Assistant"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install agentneo -U -q"
      ],
      "metadata": {
        "id": "wTC-2TkpuURw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1be116-a11f-4584-92fc-666343ff34ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m914.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.0/290.0 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# TODO: Save you OpenAI Key as a Secret\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "Fhyh7RKb_m_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authentication"
      ],
      "metadata": {
        "id": "5XSy_lQO_l7j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w5JHsBBuM_2"
      },
      "outputs": [],
      "source": [
        "from agentneo import AgentNeo, Project, Dataset, Experiment, Tracer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To login using email-id, creates new account if is not a user else retrieves the existing account\n",
        "BASE_URL = \"http://74.249.60.46:5000\"\n",
        "\n",
        "agent_session = AgentNeo(email=\"test.user5@raga.ai\", base_url=BASE_URL)"
      ],
      "metadata": {
        "id": "-491WLv5sYJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6085788a-770a-40e5-b959-3498b2d391e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User not found for email: test.user5@raga.ai. Creating new user...\n",
            "New user created for email: test.user5@raga.ai\n",
            "Please keep your access key and secret key handy for future logins:\n",
            "Access Key: YPpzZcI0TYa_8PYht2A77A\n",
            "Secret Key: WJ_LO3mb9r3-Kga0MDRxEZiFXLWlslwZSwmHZ0oJ_v8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yki2wT98uM_3"
      },
      "outputs": [],
      "source": [
        "access_key = \"YPpzZcI0TYa_8PYht2A77A\"\n",
        "secret_key = \"WJ_LO3mb9r3-Kga0MDRxEZiFXLWlslwZSwmHZ0oJ_v8\"\n",
        "\n",
        "# To login with the the access_key, secret_key\n",
        "agent_session = AgentNeo(\n",
        "        access_key=access_key,\n",
        "        secret_key=secret_key,\n",
        "        base_url=BASE_URL,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l7II2bouM_4"
      },
      "source": [
        "## Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3L3v-zYuM_5",
        "outputId": "19f6b552-c753-45b4-9055-14bf796ca449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project 'Project_77' created successfully with ID: 36\n"
          ]
        }
      ],
      "source": [
        "project_created = Project(session=agent_session, project_name=\"Project_77\", description=\"A test project\").create()\n",
        "project_id = project_created['id']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWR-C8M7uM_5"
      },
      "source": [
        "## Tracing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_openai langchain_community langgraph -q"
      ],
      "metadata": {
        "id": "A4Ymj4Ag0IJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37e6f44-5b8d-4415-dbf3-075d14197e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/2.3 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAMFpzUOuM_5",
        "outputId": "91fa0274-f47f-4e49-a2ac-fc79ef526059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Load the dataset\n",
            "# For demonstration, let's assume you have a CSV file with stock prices\n",
            "# The CSV file should have columns: 'Date', 'Company', 'Price'\n",
            "data = pd.read_csv('stock_prices.csv', parse_dates=['Date'])\n",
            "\n",
            "# Filter the data for a specific company\n",
            "company_name = 'CompanyA'  # Replace with the desired company name\n",
            "company_data = data[data['Company'] == company_name].set_index('Date')\n",
            "\n",
            "# Calculate the 30-day moving average\n",
            "company_data['30_day_moving_avg'] = company_data['Price'].rolling(window=30).mean()\n",
            "\n",
            "# Plot the original prices and the moving average\n",
            "plt.figure(figsize=(14, 7))\n",
            "plt.plot(company_data.index, company_data['Price'], label='Daily Prices', color='blue')\n",
            "plt.plot(company_data.index, company_data['30_day_moving_avg'], label='30-Day Moving Average', color='orange')\n",
            "plt.title(f'{company_name} Stock Prices and 30-Day Moving Average')\n",
            "plt.xlabel('Date')\n",
            "plt.ylabel('Price')\n",
            "plt.legend()\n",
            "plt.grid()\n",
            "plt.show()\n"
          ]
        }
      ],
      "source": [
        "#Initialise the tracer by providing the tools used and their description\n",
        "tracer = Tracer(session=agent_session, metadata= {'tools': [\n",
        "    {'name': 'structured_llm_response', 'description': \"A language model that outputs structured responses based on the Code schema.\"},\n",
        "    {'name': 'code_gen_prompt', 'description': \"Prompt template to structure the code generation response using LangChain Expression Language.\"},\n",
        "    {'name': 'check_llm_output', 'description': \"Function to check for parsing errors or tool invocation failures in the LLM's output.\"},\n",
        "]})\n",
        "\n",
        "# Langgraph code\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing import TypedDict, Annotated, Sequence\n",
        "import operator\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# LLM configuration\n",
        "openai_llm = ChatOpenAI(temperature=0.4,\n",
        "                        model_name=\"gpt-4o-mini\",\n",
        "                        api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "                        callbacks=[tracer.get_callback_handler()])\n",
        "\n",
        "# Prompt to enforce tool use\n",
        "code_gen_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"<instructions> You are a coding assistant with expertise in LCEL, LangChain expression language. \\n\n",
        "    Here is the LCEL documentation:  \\n ------- \\n  {context} \\n ------- \\n Answer the user question based on the \\n\n",
        "    above provided documentation. Ensure any code you provide can be executed with all required imports and variables \\n\n",
        "    defined. Structure your answer: 1) a prefix describing the code solution, 2) the imports, 3) the functioning code block. \\n\n",
        "    Invoke the code tool to structure the output correctly. </instructions> \\n Here is the user question:\"\"\",\n",
        "        ),\n",
        "        (\"placeholder\", \"{messages}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Data model for structured output\n",
        "class Code(BaseModel):\n",
        "    \"\"\"Code output\"\"\"\n",
        "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
        "    imports: str = Field(description=\"Code block import statements\")\n",
        "    code: str = Field(description=\"Code block not including import statements\")\n",
        "    description = \"Schema for code solutions to questions about LCEL.\"\n",
        "\n",
        "# Structured LLM with output parsing\n",
        "structured_llm = openai_llm.with_structured_output(Code, include_raw=True)\n",
        "\n",
        "# Optional: Check for errors in case tool use is flaky\n",
        "def check_llm_output(tool_output):\n",
        "    \"\"\"Check for parse error or failure to call the tool\"\"\"\n",
        "    if tool_output.get(\"parsing_error\"):\n",
        "        raw_output = tool_output[\"raw\"]\n",
        "        error = tool_output[\"parsing_error\"]\n",
        "        raise ValueError(\n",
        "            f\"Error parsing your output! Be sure to invoke the tool. Output: {raw_output}. \\n Parse error: {error}\"\n",
        "        )\n",
        "    elif not tool_output.get(\"parsed\"):\n",
        "        raise ValueError(\n",
        "            \"You did not use the provided tool! Be sure to invoke the tool to structure the output.\"\n",
        "        )\n",
        "    return tool_output\n",
        "\n",
        "# Chain with output check\n",
        "code_chain_raw = (\n",
        "    code_gen_prompt | structured_llm | check_llm_output\n",
        ")\n",
        "\n",
        "def insert_errors(inputs):\n",
        "    \"\"\"Insert errors for tool parsing in the messages\"\"\"\n",
        "    error = inputs[\"error\"]\n",
        "    messages = inputs[\"messages\"]\n",
        "    messages += [\n",
        "        (\n",
        "            \"assistant\",\n",
        "            f\"Retry. You are required to fix the parsing errors: {error} \\n\\n You must invoke the provided tool.\",\n",
        "        )\n",
        "    ]\n",
        "    return {\n",
        "        \"messages\": messages,\n",
        "        \"context\": inputs[\"context\"],\n",
        "    }\n",
        "\n",
        "# This will be run as a fallback chain\n",
        "fallback_chain = insert_errors | code_chain_raw\n",
        "N = 3  # Max retries\n",
        "code_gen_chain_re_try = code_chain_raw.with_fallbacks(\n",
        "    fallbacks=[fallback_chain] * N, exception_key=\"error\"\n",
        ")\n",
        "\n",
        "def parse_output(solution):\n",
        "    \"\"\"When we add 'include_raw=True' to structured output,\n",
        "    it will return a dict w 'raw', 'parsed', 'parsing_error'.\"\"\"\n",
        "    return solution.get(\"parsed\")\n",
        "\n",
        "# Optional: With retry to correct for failure to invoke tool\n",
        "code_gen_chain = code_gen_chain_re_try | parse_output\n",
        "\n",
        "# No retry\n",
        "code_gen_chain_no_retry = code_gen_prompt | structured_llm | parse_output\n",
        "\n",
        "# Integration with Tracer and StateGraph\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[str], operator.add]\n",
        "    context: str\n",
        "\n",
        "@tracer.trace_node\n",
        "def agent(state):\n",
        "    query = state[\"messages\"]\n",
        "    context = state[\"context\"]\n",
        "    prompt_value = code_gen_prompt.format(messages=query, context=context)\n",
        "    res = openai_llm.invoke(prompt_value)\n",
        "    # Accessing the actual content within the response object\n",
        "    return {\"messages\": [res.content], \"context\": context}\n",
        "\n",
        "@tracer.trace_node\n",
        "def structured_llm_response(state):\n",
        "    query = state[\"messages\"]\n",
        "    # Assuming query is a list of strings, you can directly pass it as a formatted prompt string\n",
        "    prompt_value = code_gen_prompt.format(messages=query, context=state[\"context\"])\n",
        "    result = structured_llm.invoke(prompt_value)\n",
        "    parsed_result = parse_output(result)\n",
        "    return {\"messages\": [parsed_result.code], \"context\": state[\"context\"]}\n",
        "\n",
        "@tracer.trace_graph\n",
        "def workflow():\n",
        "    graph = StateGraph(AgentState)\n",
        "    graph.add_node(\"agent\", agent)\n",
        "    graph.add_node(\"structured_llm_response\", structured_llm_response)\n",
        "    graph.add_edge(\"agent\", \"structured_llm_response\")\n",
        "    graph.set_entry_point(\"agent\")\n",
        "    graph.set_finish_point(\"structured_llm_response\")\n",
        "    return graph.compile()\n",
        "\n",
        "compiled_workflow = workflow()\n",
        "\n",
        "@tracer.trace_node\n",
        "def get_output(message, context):\n",
        "    inputs = {\"messages\": [message], \"context\": context}\n",
        "    response = compiled_workflow.invoke(inputs)\n",
        "    print(response[\"messages\"][-1])\n",
        "\n",
        "# Example usage for code assistance\n",
        "# context = \"You are working on a natural language processing project that requires the use of the LangChain Expression Language (LCEL) to dynamically build and evaluate logical expressions. LCEL allows you to create, manipulate, and evaluate expressions that can be embedded into larger workflows or applications. You have access to the LCEL documentation, which provides detailed information on its syntax, functions, and usage patterns.You are familiar with basic programming concepts and have some experience in Python, but LCEL is relatively new to you. You are looking to leverage LCEL to perform complex data manipulations and logical operations in your project.\"\n",
        "# get_output('You are trying to create a logical expression in LCEL that checks if a list of strings contains any elements that match a specific pattern. For instance, you want to check if the list contains any strings that start with the prefix \"LC_\" and end with the suffix \"_2024\". How can you construct and evaluate this expression using LCEL? Please provide a code example that includes all necessary imports and defines the required variables.', context)\n",
        "context =\"You are participating in a data analysis project where you need to work with time series data. The dataset contains daily stock prices for multiple companies over several years. You are using the Pandas library in Python for data manipulation and analysis. You have experience with basic data operations in Pandas, such as filtering and aggregating data, but now you need to perform more complex time series analysis, including calculating moving averages and identifying trends.\"\n",
        "get_output('You want to calculate a 30-day moving average of the stock prices and plot it along with the original daily prices for a specific company. How can you achieve this using Pandas? Provide a code example that includes all necessary imports and data manipulation steps.', context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ehs6ymNuM_5",
        "outputId": "7d7e3c6d-ae79-4c2b-983f-925dc12ffb14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trace uploaded successfully. Trace ID: 41\n"
          ]
        }
      ],
      "source": [
        "trace_id = tracer.upload_trace()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHEYhW_JuM_6"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btGEsFjbuM_6"
      },
      "outputs": [],
      "source": [
        "# Create a dataset from a trace\n",
        "dataset = Dataset(\n",
        "    session=agent_session,\n",
        "    project_id=project_id,\n",
        "    dataset_name=\"Dataset_1\",\n",
        "    description=\"A test dataset\"\n",
        ")\n",
        "\n",
        "dataset_traced = dataset.from_trace(trace_id=tracer.id, trace_filter=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gBisuQHuM_6"
      },
      "source": [
        "## Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aTN2NJmuM_6"
      },
      "outputs": [],
      "source": [
        "# Create Experiment\n",
        "experiment = Experiment(\n",
        "        session=agent_session,\n",
        "        experiment_name=\"Experiment_3\",\n",
        "        description=\"A test experiment\",\n",
        "        dataset_id=dataset_traced['id'],\n",
        "        project_id=project_id\n",
        "    )\n",
        "\n",
        "experiment_created = experiment.create()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_499m8qbuM_6"
      },
      "outputs": [],
      "source": [
        "# Execute Experiment\n",
        "exp = experiment.execute(metrics=[\n",
        "    {\"name\": \"summarise\", \"config\": {}},\n",
        "    {\"name\": \"tool_selection_accuracy\", \"config\": {\"model\": \"gpt-4o-mini\", \"OPENAI_API_KEY\": os.environ[\"OPENAI_API_KEY\"]}},\n",
        "    {\"name\": \"tool_usage_efficiency\", \"config\": {\"model\": \"gpt-4o-mini\", \"OPENAI_API_KEY\": os.environ[\"OPENAI_API_KEY\"]}},\n",
        "    {\"name\": \"goal_decomposition_efficiency\", \"config\": {\"model\": \"gpt-4o-mini\", \"OPENAI_API_KEY\": os.environ[\"OPENAI_API_KEY\"]}},\n",
        "    {\"name\": \"plan_adaptibility\", \"config\": {\"model\": \"gpt-4o-mini\", \"OPENAI_API_KEY\": os.environ[\"OPENAI_API_KEY\"]}},\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5XYT8j6uM_6",
        "outputId": "b3f718b9-6fe2-4a36-9035-473c9b3464d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: summarise\n",
            "Result:\n",
            "completion_cost: 0.0028155\n",
            "completion_tokens: 1877\n",
            "input_cost: 0.001877\n",
            "input_tokens: 3754\n",
            "latency: 0.004678487777709961\n",
            "summary: {'children': 'list with 1 items', 'end': 'NoneType', 'inputs': 'NoneType', 'name': 'str', 'outputs': 'NoneType', 'start': 'NoneType', 'type': 'str'}\n",
            "total_cost: 0.0046925\n",
            "total_tokens: 5631\n",
            "****************************************************************************************************\n",
            "\n",
            "Name: tool_selection_accuracy\n",
            "Result:\n",
            "reasoning: [\"The selected tool, 'structured_llm_response', is highly appropriate for the task of generating a code example for calculating a 30-day moving average of stock prices using Pandas. The tool aligns perfectly with the user's request for structured output, and the AI's thought process demonstrates a clear understanding of the task requirements.\"]\n",
            "score: 0.9999999900000002\n",
            "selected_tools: [\"structured_llm_response\"]\n",
            "****************************************************************************************************\n",
            "\n",
            "Name: tool_usage_efficiency\n",
            "Result:\n",
            "inefficiency_identified: There was a slight inefficiency in that the AI could have potentially used the check_llm_output tool to verify the generated code for errors, but it did not do so.\n",
            "justification: The AI effectively used the structured_llm_response tool to generate a comprehensive code example that included all necessary steps for calculating a 30-day moving average and plotting the results. The sequence of operations was logical, and the parameters were well-chosen for the task at hand.\n",
            "score: 0.95\n",
            "tools_used: ['structured_llm_response']\n",
            "****************************************************************************************************\n",
            "\n",
            "Name: goal_fulfillment_rate\n",
            "Result:\n",
            "originalGoal: Calculate a 30-day moving average of stock prices and visualize it alongside the original daily prices for a specific company using the Pandas library in Python.\n",
            "reason: The AI effectively decomposed the original goal into five clear and logical sub-tasks that cover all aspects of the task. Each sub-task is appropriately assigned to the relevant tools, ensuring that the user can follow a structured approach to achieve their goal. The decomposition is complete, granular, and avoids redundancy, making it highly efficient for the user to execute the tasks independently.\n",
            "score: 1.0\n",
            "subtasks: ['Import the necessary libraries.', 'Load the dataset containing the stock prices.', 'Filter the data for the specific company.', 'Calculate the 30-day moving average.', 'Plot the original prices and the moving average.']\n",
            "****************************************************************************************************\n",
            "\n",
            "Name: plan_adaptibility\n",
            "Result:\n",
            "initial_plan: 1. Import the necessary libraries.\n",
            "2. Load the dataset containing the stock prices.\n",
            "3. Filter the data for the specific company.\n",
            "4. Calculate the 30-day moving average.\n",
            "5. Plot the original prices and the moving average.\n",
            "justification: No plan alterations required\n",
            "score: 0\n",
            "****************************************************************************************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Experiment Results\n",
        "exp = experiment.get_results(experiment_id=exp['id'])\n",
        "\n",
        "for i in exp['results']:\n",
        "    print(f\"Name: {i['metric_name']}\")\n",
        "    print(f\"Result:\")\n",
        "    for key, value in i['result'].items():\n",
        "        print(f\"{key}: {value}\")\n",
        "    print(f\"{'*'*100}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Udigis3P1D5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa0oCgeBuM_0"
      },
      "source": [
        "# AgentNeo: Getting Started"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install agentneo -U -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTC-2TkpuURw",
        "outputId": "4ef8ec4d-8150-4cb0-edb4-864829023939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting agentneo\n",
            "  Downloading agentneo-0.1.3.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: requests>=2.25.1 in /usr/local/lib/python3.10/dist-packages (from agentneo) (2.32.3)\n",
            "Collecting langchain>=0.2.1 (from agentneo)\n",
            "  Downloading langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting requests-toolbelt~=1.0.0 (from agentneo)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting openai~=1.43.0 (from agentneo)\n",
            "  Downloading openai-1.43.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.2.1->agentneo) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.2.1->agentneo) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.2.1->agentneo) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.2.1->agentneo) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.38 (from langchain>=0.2.1->agentneo)\n",
            "  Downloading langchain_core-0.2.38-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain>=0.2.1->agentneo)\n",
            "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain>=0.2.1->agentneo)\n",
            "  Downloading langsmith-0.1.111-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.2.1->agentneo) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.2.1->agentneo) (2.8.2)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain>=0.2.1->agentneo)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai~=1.43.0->agentneo) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai~=1.43.0->agentneo) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai~=1.43.0->agentneo)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai~=1.43.0->agentneo)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai~=1.43.0->agentneo) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai~=1.43.0->agentneo) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai~=1.43.0->agentneo) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->agentneo) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->agentneo) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->agentneo) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->agentneo) (2024.7.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.2.1->agentneo) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.2.1->agentneo) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.2.1->agentneo) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.2.1->agentneo) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.2.1->agentneo) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.2.1->agentneo) (1.9.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai~=1.43.0->agentneo) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai~=1.43.0->agentneo)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai~=1.43.0->agentneo)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.38->langchain>=0.2.1->agentneo)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain>=0.2.1->agentneo) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain>=0.2.1->agentneo)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m952.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain>=0.2.1->agentneo) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain>=0.2.1->agentneo) (2.20.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain>=0.2.1->agentneo) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain>=0.2.1->agentneo)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading agentneo-0.1.3.1-py3-none-any.whl (17 kB)\n",
            "Downloading langchain-0.2.16-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.43.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.38-py3-none-any.whl (396 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.111-py3-none-any.whl (288 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.5/288.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: tenacity, orjson, jsonpointer, jiter, h11, requests-toolbelt, jsonpatch, httpcore, httpx, openai, langsmith, langchain-core, langchain-text-splitters, langchain, agentneo\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed agentneo-0.1.3.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.16 langchain-core-0.2.38 langchain-text-splitters-0.2.4 langsmith-0.1.111 openai-1.43.0 orjson-3.10.7 requests-toolbelt-1.0.0 tenacity-8.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w5JHsBBuM_2"
      },
      "outputs": [],
      "source": [
        "from agentneo import AgentNeo, Project, Dataset, Experiment, Tracer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To login using email-id, creates new account if is not a user else retrieves the existing account\n",
        "BASE_URL = \"http://74.249.60.46:5000\"\n",
        "\n",
        "agent_session = AgentNeo(email=\"user1@example.com\", base_url=BASE_URL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-491WLv5sYJZ",
        "outputId": "72993e61-bc2b-4696-dddf-8d55bb59296d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing user found for email: user1@example.com\n",
            "Please keep your access key and secret key handy for future logins:\n",
            "Access Key: 2USyfi19AxtWqtuo3WTGww\n",
            "Secret Key: F_YZRdqZcPk5Vz7YXT4I4VGRin0e9C4T_sqOBDHiOIc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yki2wT98uM_3"
      },
      "outputs": [],
      "source": [
        "access_key = \"2USyfi19AxtWqtuo3WTGww\"\n",
        "secret_key = \"F_YZRdqZcPk5Vz7YXT4I4VGRin0e9C4T_sqOBDHiOIc\"\n",
        "\n",
        "# To login with the the access_key, secret_key\n",
        "agent_session = AgentNeo(\n",
        "        access_key=access_key,\n",
        "        secret_key=secret_key,\n",
        "        base_url=BASE_URL,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l7II2bouM_4"
      },
      "source": [
        "## Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "Z3L3v-zYuM_5",
        "outputId": "b9e60f8e-cd7b-4755-b68e-430877accd3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred while creating the project: Request failed: {'error': 'You already have a project with this name'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'id'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7488df144e17>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mproject_created\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Project_2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"A test project\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mproject_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject_created\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'id'"
          ]
        }
      ],
      "source": [
        "project_created = Project(session=agent_session, project_name=\"Project_2\", description=\"A test project\").create()\n",
        "project_id = project_created['id']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWR-C8M7uM_5"
      },
      "source": [
        "## Tracing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "YuzlPB--0Bch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai langchain_community langgraph arxiv -q"
      ],
      "metadata": {
        "id": "A4Ymj4Ag0IJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAMFpzUOuM_5",
        "outputId": "57f3834f-c584-4398-e1a1-0f3a6eadc085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the search results provided, it seems that there are researchers working on the propagation of LASER through brownian fluids. \n",
            "\n",
            "1. The first study published in 2017 focuses on quantifying the temporal structural diversity of a laser beam propagating through isotropic optical turbulence. The researchers conducted a laboratory-controlled experiment to analyze coordinate fluctuations of the laser beam and observed a transition from an integrated stochastic process to a fractional Brownian motion as the sampling time increased.\n",
            "\n",
            "2. The second study published in 2021 experimentally studied the impact of inertial reference frame changes on overdamped Brownian motion using a laser to induce convection flows in a column of fluid. The researchers verified the weak Galilean invariance of Brownian dynamics and derived a Galilean invariant expression of the stochastic thermodynamic first law.\n",
            "\n",
            "3. The third study published in 2008 measured the overall motion of Brownian particles suspended in water using a self-mixing thin-slice solid-state laser. The researchers observed different overall dynamics of the particles based on the scale of observation and characterized the motion of a virtual single particle exhibiting fractional Brownian motion.\n",
            "\n",
            "Overall, these studies provide insights into the behavior of laser propagation through brownian fluids and the dynamics of Brownian motion in different experimental setups.\n"
          ]
        }
      ],
      "source": [
        "# Initialise the tracer by providing the tools-used and their description\n",
        "tracer = Tracer(session=agent_session, metadata={'tools': [\n",
        "    {'name': 'arxiv_tool', 'description': \"Tool to search Arxiv for available research papers.\"},\n",
        "    {'name': 'agent', 'description': \"Identify the search terms for arxiv from the user description and call the arxiv_tool based on the search term\"},\n",
        "]})\n",
        "\n",
        "# Langgraph code\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.utilities.arxiv import ArxivAPIWrapper\n",
        "from typing import TypedDict, Annotated, Sequence\n",
        "import operator\n",
        "from langgraph.graph import StateGraph, END\n",
        "import os\n",
        "\n",
        "openai_llm = ChatOpenAI(temperature=0.4, callbacks=[tracer.get_callback_handler()])\n",
        "arxiv = ArxivAPIWrapper(\n",
        "    top_k_results=3,\n",
        "    ARXIV_MAX_QUERY_LENGTH=300,\n",
        "    load_max_docs=3,\n",
        "    load_all_available_meta=False,\n",
        "    doc_content_chars_max=40000\n",
        ")\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[str], operator.add]\n",
        "\n",
        "@tracer.trace_node\n",
        "def agent(state):\n",
        "    query = state[\"messages\"]\n",
        "    res = openai_llm.invoke(f\"\"\"\n",
        "    You are given text summary on the research topics that the user is working on.\n",
        "    You need to extract the search term from the text summary.\n",
        "    Here is the Text summary: {query[0]}\n",
        "    \"\"\")\n",
        "    return {\"messages\": [res.content]}\n",
        "\n",
        "@tracer.trace_node\n",
        "def arxiv_tool(state):\n",
        "    context = state[\"messages\"]\n",
        "    search_query = context[1]\n",
        "    data = arxiv.run(search_query)\n",
        "    return {\"messages\": [data]}\n",
        "\n",
        "@tracer.trace_node\n",
        "def responder(state):\n",
        "    agent = openai_llm.invoke(f\"\"\"\n",
        "    You are given search results on the research topics that the user is working on.\n",
        "\n",
        "    Here is the user query:\n",
        "    ---\n",
        "    {state[\"messages\"][0]}\n",
        "    ---\n",
        "\n",
        "    Here is the search results:\n",
        "    ---\n",
        "    {state[\"messages\"][2]}\n",
        "    ---\n",
        "    \"\"\")\n",
        "    return {\"messages\": [agent.content]}\n",
        "@tracer.trace_node\n",
        "def where_to_go(state):\n",
        "    ctx = state[\"messages\"][0]\n",
        "    if ctx == \"no_response\":\n",
        "        return \"end\"\n",
        "    else:\n",
        "        return \"continue\"\n",
        "\n",
        "@tracer.trace_graph\n",
        "def workflow():\n",
        "    graph = StateGraph(AgentState)\n",
        "    graph.add_node(\"agent\", agent)\n",
        "    graph.add_node(\"arxiv\", arxiv_tool)\n",
        "    graph.add_node(\"responder\", responder)\n",
        "    graph.add_conditional_edges(\"agent\", where_to_go, {\n",
        "        \"end\": END,\n",
        "        \"continue\": \"arxiv\"\n",
        "    })\n",
        "    graph.add_edge(\"agent\", \"arxiv\")\n",
        "    graph.add_edge(\"arxiv\", \"responder\")\n",
        "    graph.set_entry_point(\"agent\")\n",
        "    graph.set_finish_point(\"responder\")\n",
        "    return graph.compile()\n",
        "\n",
        "compiled_workflow = workflow()\n",
        "\n",
        "@tracer.trace_node\n",
        "def get_output(message):\n",
        "    inputs = {\"messages\": [message]}\n",
        "    response = compiled_workflow.invoke(inputs)\n",
        "    print(response[\"messages\"][-1])\n",
        "\n",
        "get_output(\"Is someone working on the propagation of LASER through brownian fluids\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ehs6ymNuM_5",
        "outputId": "97cb78d5-8072-4e88-8a66-c343755ebb9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trace uploaded successfully. Trace ID: 11\n"
          ]
        }
      ],
      "source": [
        "trace_id = tracer.upload_trace()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHEYhW_JuM_6"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btGEsFjbuM_6"
      },
      "outputs": [],
      "source": [
        "# Create a dataset from a trace\n",
        "dataset = Dataset(\n",
        "    session=agent_session,\n",
        "    project_id=project_id,\n",
        "    dataset_name=\"Dataset_1\",\n",
        "    description=\"A test dataset\"\n",
        ")\n",
        "\n",
        "dataset_traced = dataset.from_trace(trace_id=tracer.id, trace_filter=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gBisuQHuM_6"
      },
      "source": [
        "## Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aTN2NJmuM_6"
      },
      "outputs": [],
      "source": [
        "# Create Experiment\n",
        "experiment = Experiment(\n",
        "        session=agent_session,\n",
        "        experiment_name=\"Experiment_1\",\n",
        "        description=\"A test experiment\",\n",
        "        dataset_id=dataset_traced['id'],\n",
        "        project_id=project_id\n",
        "    )\n",
        "\n",
        "experiment_created = experiment.create()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_499m8qbuM_6"
      },
      "outputs": [],
      "source": [
        "# Execute Experiment\n",
        "exp = experiment.execute(metrics=[\n",
        "    {\"name\": \"summarise\", \"config\": {}},\n",
        "    {\"name\": \"tool_selection_accuracy\", \"config\": {\"model\": \"gpt-4o-mini\", \"OPENAI_API_KEY\": os.environ.get(\"OPENAI_API_KEY\")}},\n",
        "    {\"name\": \"tool_usage_efficiency\", \"config\": {\"model\": \"gpt-4o-mini\", \"OPENAI_API_KEY\": os.environ.get(\"OPENAI_API_KEY\")}},\n",
        "    {\"name\": \"goal_decomposition_efficiency\", \"config\": {\"model\": \"gpt-4o-mini\", \"OPENAI_API_KEY\": os.environ.get(\"OPENAI_API_KEY\")}},\n",
        "    {\"name\": \"plan_adaptibility\", \"config\": {\"model\": \"gpt-4o-mini\", \"OPENAI_API_KEY\": os.environ.get(\"OPENAI_API_KEY\")}},\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5XYT8j6uM_6",
        "outputId": "b9ee2027-7aa4-4d4a-f2a3-845219feebb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: summarise\n",
            "Result:\n",
            "completion_cost: 0.0032025\n",
            "completion_tokens: 2135\n",
            "input_cost: 0.0021349999999999997\n",
            "input_tokens: 4270\n",
            "latency: 0.006265878677368164\n",
            "summary: {'children': 'list with 1 items', 'end': 'NoneType', 'inputs': 'NoneType', 'name': 'str', 'outputs': 'NoneType', 'start': 'NoneType', 'type': 'str'}\n",
            "total_cost: 0.0053375\n",
            "total_tokens: 6405\n",
            "****************************************************************************************************\n",
            "\n",
            "Name: tool_selection_accuracy\n",
            "Result:\n",
            "reasoning: [\"The selected tool 'agent' is relevant as it identifies search terms for the arxiv_tool based on the user's inquiry about ongoing research. However, it could be argued that directly using the arxiv_tool would have been more efficient since the user is specifically looking for research papers.\", \"The selection of the arxiv_tool is optimal as it directly addresses the user's request for research related to the propagation of LASER through Brownian fluids. The tool successfully retrieves relevant publications, fulfilling the task requirements effectively.\"]\n",
            "score: 0.8749999956250001\n",
            "selected_tools: [\"agent\", \"arxiv_tool\"]\n",
            "****************************************************************************************************\n",
            "\n",
            "Name: tool_usage_efficiency\n",
            "Result:\n",
            "improvement_suggestion: To improve efficiency, the AI could streamline the process by directly using the 'arxiv_tool' with a well-defined search term based on the user's query, eliminating the need for the initial 'agent' call.\n",
            "inefficiency_identified: The initial call to the 'agent' tool was somewhat redundant, as the search term could have been directly formulated and passed to the 'arxiv_tool' without an intermediary step.\n",
            "justification: The AI effectively utilized the 'agent' tool to identify the search term and subsequently called the 'arxiv_tool' to retrieve relevant research papers. The sequence of tool usage was logical, and the parameters used were appropriate for the task. However, there was a slight inefficiency in the initial tool call, as the AI could have directly used the 'arxiv_tool' with a well-defined search term without needing the intermediary step.\n",
            "most_efficient_use: The use of the 'arxiv_tool' to retrieve relevant research papers was the most efficient, as it provided comprehensive results directly related to the user's query.\n",
            "score: 0.85\n",
            "tools_used: ['agent', 'arxiv_tool']\n",
            "****************************************************************************************************\n",
            "\n",
            "Name: goal_fulfillment_rate\n",
            "Result:\n",
            "originalGoal: The user is seeking information about ongoing research related to the propagation of laser light through Brownian fluids, specifically interested in identifying researchers and published findings.\n",
            "reason: The decomposition of the original goal into sub-tasks is mostly effective, with clear assignments of tools to each sub-task. The tasks are logically sequenced, and the AI successfully identifies relevant studies and summarizes them. However, the first sub-task could be considered somewhat redundant since the search term is already implied in the user's query. Overall, the sub-tasks cover the necessary aspects of the original goal, achieving a high level of completeness and clarity.\n",
            "score: 0.85\n",
            "subtasks: [\"Identify the search term related to the user's query.\", 'Conduct a search for relevant studies on the propagation of LASER through Brownian fluids.', 'Summarize findings from identified studies, including publication dates, titles, authors, and key insights.', 'Present the summarized research to the user, highlighting ongoing work and significant results.']\n",
            "****************************************************************************************************\n",
            "\n",
            "Name: plan_adaptibility\n",
            "Result:\n",
            "initial_plan: None\n",
            "justification: No plan found in the traces\n",
            "score: 0\n",
            "****************************************************************************************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Experiment Results\n",
        "exp = experiment.get_results(experiment_id=exp['id'])\n",
        "\n",
        "for i in exp['results']:\n",
        "    print(f\"Name: {i['metric_name']}\")\n",
        "    print(f\"Result:\")\n",
        "    for key, value in i['result'].items():\n",
        "        print(f\"{key}: {value}\")\n",
        "    print(f\"{'*'*100}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmui7xmVuM_6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}